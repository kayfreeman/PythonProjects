{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97faca-ea8d-4191-9267-ce4406225564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager  # ✅ New import\n",
    "\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "\n",
    "# Path to service account JSON\n",
    "SERVICE_ACCOUNT_FILE = r\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx.json\"\n",
    "\n",
    "# Google Sheet info\n",
    "SPREADSHEET_KEY = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "WORKSHEET_NAME = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "# NGX URL\n",
    "URL = \"https://ngxgroup.com/exchange/data/equities-price-list/\"\n",
    "\n",
    "# Directories for data and logs\n",
    "BASE_DIR = os.getcwd()\n",
    "LOG_DIR = os.path.join(BASE_DIR, \"logs\")\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Filenames\n",
    "today_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "CSV_FILE = os.path.join(DATA_DIR, f\"data_{today_str}.csv\")\n",
    "LOG_FILE = os.path.join(LOG_DIR, \"web_scrap_log.txt\")\n",
    "\n",
    "\n",
    "# === Logging helper ===\n",
    "def log_message(message: str):\n",
    "    \"\"\"Append timestamped messages to log file using UTF-8 encoding\"\"\"\n",
    "    with open(LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{datetime.now():%Y-%m-%d %H:%M:%S} - {message}\\n\")\n",
    "\n",
    "\n",
    "# === Handle Cookie Consent ===\n",
    "def handle_cookie_consent(driver, wait):\n",
    "    try:\n",
    "        cookie_button = wait.until(\n",
    "            EC.element_to_be_clickable((By.ID, \"cookie_action_close_header\"))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", cookie_button)\n",
    "        log_message(\"✅ Closed cookie popup\")\n",
    "    except Exception as e:\n",
    "        log_message(f\"ℹ️ Cookie popup not found or error: {e}\")\n",
    "\n",
    "\n",
    "# === Main Scraper Function ===\n",
    "def scrape_and_push():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--incognito\")\n",
    "\n",
    "    # ✅ Use ChromeDriverManager instead of a fixed chromedriver.exe path\n",
    "    driver = webdriver.Chrome(\n",
    "        service=webdriver.chrome.service.Service(ChromeDriverManager().install()),\n",
    "        options=options,\n",
    "    )\n",
    "    wait = WebDriverWait(driver, 20)\n",
    "\n",
    "    try:\n",
    "        driver.get(URL)\n",
    "        handle_cookie_consent(driver, wait)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Expand table to show all rows\n",
    "        try:\n",
    "            filter_option = wait.until(EC.element_to_be_clickable((\n",
    "                By.XPATH, \"//*[@id='latestdiclosuresEquities_length']/label/select/option[last()]\"\n",
    "            )))\n",
    "            filter_option.click()\n",
    "            time.sleep(2)\n",
    "            log_message(\"✅ Table expanded to show all rows\")\n",
    "        except Exception:\n",
    "            log_message(\"⚠️ Could not expand table rows\")\n",
    "\n",
    "        # Scrape table\n",
    "        table = wait.until(EC.presence_of_element_located((By.ID, \"latestdiclosuresEquities\")))\n",
    "        table_html = table.get_attribute(\"outerHTML\")\n",
    "        soup = BeautifulSoup(table_html, \"html.parser\")\n",
    "\n",
    "        headers = [th.get_text(strip=True) for th in soup.find(\"thead\").find_all(\"th\")]\n",
    "        rows = []\n",
    "        for row in soup.find(\"tbody\").find_all(\"tr\"):\n",
    "            cells = row.find_all(\"td\")\n",
    "            rows.append([cell.get_text(strip=True) for cell in cells])\n",
    "\n",
    "        if headers and rows:\n",
    "            df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "            # Clean company names\n",
    "            if \"Company\" in df.columns:\n",
    "                df[\"Company\"] = df[\"Company\"].str.strip()\n",
    "\n",
    "            df[\"Date\"] = today_str\n",
    "            df.to_csv(CSV_FILE, index=False, encoding=\"utf-8\")\n",
    "            log_message(f\"✅ Data saved locally ({len(df)} rows)\")\n",
    "\n",
    "            # === Push to Google Sheets ===\n",
    "            try:\n",
    "                scope = [\n",
    "                    \"https://spreadsheets.google.com/feeds\",\n",
    "                    \"https://www.googleapis.com/auth/spreadsheets\",\n",
    "                    \"https://www.googleapis.com/auth/drive.file\",\n",
    "                    \"https://www.googleapis.com/auth/drive\",\n",
    "                ]\n",
    "                creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=scope)\n",
    "                client = gspread.authorize(creds)\n",
    "\n",
    "                spreadsheet = client.open_by_key(SPREADSHEET_KEY)\n",
    "                sheet = spreadsheet.worksheet(WORKSHEET_NAME)\n",
    "\n",
    "                # Clear existing data\n",
    "                sheet.clear()\n",
    "\n",
    "                # Update headers and data\n",
    "                sheet.update(values=[df.columns.tolist()], range_name=\"A1\")\n",
    "                sheet.update(values=df.values.tolist(), range_name=\"A2\")\n",
    "\n",
    "                log_message(f\"✅ NGXUPDATE sheet successfully updated with {len(df)} rows\")\n",
    "                print(f\"✅ NGXUPDATE sheet successfully updated with {len(df)} rows\")\n",
    "\n",
    "            except Exception as e:\n",
    "                log_message(f\"❌ Google Sheets update failed: {e}\")\n",
    "                print(f\"❌ Google Sheets update failed: {e}\")\n",
    "        else:\n",
    "            log_message(\"⚠️ No data found in table\")\n",
    "            print(\"⚠️ No data found in table\")\n",
    "\n",
    "    except Exception as e:\n",
    "        log_message(f\"❌ Scraping failed: {e}\")\n",
    "        print(f\"❌ Scraping failed: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        log_message(\"Browser closed.\")\n",
    "\n",
    "\n",
    "# === MAIN ===\n",
    "if __name__ == \"__main__\":\n",
    "    with open(LOG_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{today_str} - Log started\\n\")\n",
    "    scrape_and_push()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
